<!doctype html><html lang=en data-theme><head><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><title>Introduction to the theory of decision-making - Baptiste Pesquet</title><meta name=description content="Introduction to the theory of decision-making Terminology Decision and decision-making A decision is &ldquo;a deliberative process that results in the commitment to a categorical proposition.&rdquo; [Gold and Shadlen, 2007]
People make thousands of (big and small) decisions everyday. A few examples:
Choosing what pair of socks to wear. Deciding on a TV series to watch. Choosing one&rsquo;s next car/bike. Decision-making designates the cognitive process(es) resulting in a decision.
The sequential nature of decision-making Humans and animals make their decisions after a deliberation phase."><link rel=icon type=image/x-icon href=https://www.bpesquet.fr/favicon.ico><link rel=apple-touch-icon-precomposed href=https://www.bpesquet.fr/favicon.png><style>body{visibility:hidden;opacity:0}</style><noscript><style>body{visibility:visible;opacity:1}</style></noscript><link rel=stylesheet href=https://www.bpesquet.fr/css/style.min.ecd6d68ec75f136aa2ef44e76818d4e46cf4ee45f39dae3684c8b4232785015c.css integrity="sha256-7NbWjsdfE2qi70TnaBjU5Gz07kXzna42hMi0IyeFAVw="><script src=https://www.bpesquet.fr/js/script.min.74bf1a3fcf1af396efa4acf3e660e876b61a2153ab9cbe1893ac24ea6d4f94ee.js type=text/javascript integrity="sha256-dL8aP88a85bvpKzz5mDodrYaIVOrnL4Yk6wk6m1PlO4="></script><meta property="og:title" content="Introduction to the theory of decision-making"><meta property="og:description" content="Introduction to the theory of decision-making Terminology Decision and decision-making A decision is &ldquo;a deliberative process that results in the commitment to a categorical proposition.&rdquo; [Gold and Shadlen, 2007]
People make thousands of (big and small) decisions everyday. A few examples:
Choosing what pair of socks to wear. Deciding on a TV series to watch. Choosing one&rsquo;s next car/bike. Decision-making designates the cognitive process(es) resulting in a decision.
The sequential nature of decision-making Humans and animals make their decisions after a deliberation phase."><meta property="og:type" content="article"><meta property="og:url" content="https://www.bpesquet.fr/talks/decision-making/"><meta property="article:section" content="talks"><meta property="article:published_time" content="2024-01-29T10:13:06+01:00"><meta property="article:modified_time" content="2024-12-04T08:28:02+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Introduction to the theory of decision-making"><meta name=twitter:description content="Introduction to the theory of decision-making Terminology Decision and decision-making A decision is &ldquo;a deliberative process that results in the commitment to a categorical proposition.&rdquo; [Gold and Shadlen, 2007]
People make thousands of (big and small) decisions everyday. A few examples:
Choosing what pair of socks to wear. Deciding on a TV series to watch. Choosing one&rsquo;s next car/bike. Decision-making designates the cognitive process(es) resulting in a decision.
The sequential nature of decision-making Humans and animals make their decisions after a deliberation phase."><script async src="https://www.googletagmanager.com/gtag/js?id=G-4DNVMNCRYK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-4DNVMNCRYK",{anonymize_ip:!1})}</script></head><body><a class=skip-main href=#main>Skip to main content</a><div class=container><header class=common-header><div class=header-top><div class=header-top-left><h1 class=site-title><a href=/>Baptiste Pesquet</a></h1><ul class=social-icons><li><a href="mailto:bpesquet [at] gmail [dot] com" title=Email rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M464 64H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 4e2V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V4e2H48z"/></svg></span></a></li><li><a href=https://github.com/bpesquet title=Github rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li><li><a href="https://scholar.google.fr/citations?hl=fr&amp;user=0KJ7JkMAAAAJ" title="Google scholar" rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M390.9 298.5s0 .1.1.1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7 4.4-7.6 9.4-14.7 15-21.3 27.4-32.6 68.5-53.3 114.4-53.3 33.6.0 64.6 11.1 89.6 29.9 9.1 6.9 17.4 14.7 24.8 23.5 5.6 6.6 10.6 13.8 15 21.3 2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/></svg></span></a></li><li><a href=https://www.linkedin.com/in/bpesquet title=Linkedin rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M100.3 448H7.4V148.9h92.9zM53.8 108.1C24.1 108.1.0 83.5.0 53.8a53.8 53.8.0 01107.6.0c0 29.7-24.1 54.3-53.8 54.3zM447.9 448h-92.7V302.4c0-34.7-.7-79.2-48.3-79.2-48.3.0-55.7 37.7-55.7 76.7V448h-92.8V148.9h89.1v40.8h1.3c12.4-23.5 42.7-48.3 87.9-48.3 94 0 111.3 61.9 111.3 142.3V448z"/></svg></span></a></li><li><a href=https://bsky.app/profile/bpesquet.bsky.social title=Bluesky rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill="currentcolor" d="M123.6 34.5C190 84.6 261.5 186 287.8 240.5 314 186 385.5 84.5 452 34.5c48-36.1 125.6-64.1 125.6 24.9.0 17.8-10.1 149.2-16.1 170.5-20.7 74.2-96.1 93.1-163.1 81.6 117.2 20 147 86.3 82.6 152.6-122.3 125.9-175.8-31.6-189.5-72-2.5-7.5-3.7-10.9-3.7-7.9.0-3.1-1.2.4-3.7 7.9-13.7 40.4-67.2 197.9-189.5 72C30.2 397.8 60 331.5 177.2 311.5c-67 11.4-142.4-7.5-163.1-81.7C8.1 208.5-2 77.1-2 59.3c0-88.9 77.7-61 125.6-24.9z"/></svg></span></a></li><li><a href=https://www.youtube.com/c/../@bpesquet title=Youtube rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg></span></a></li></ul></div><div class=header-top-right><div class=theme-switcher><span class=inline-svg><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 290 290"><path fill="currentcolor" d="M142.959.0C64.131.0.0 64.132.0 142.96s64.131 142.959 142.959 142.959 142.96-64.131 142.96-142.959C285.919 64.132 221.787.0 142.959.0zm0 260.919V142.96 25c65.043.0 117.96 52.917 117.96 117.96.0 65.043-52.917 117.959-117.96 117.959z"/></svg></span></div><script>const STORAGE_KEY="user-color-scheme",defaultTheme="auto";let currentTheme,switchButton,autoDefinedScheme=window.matchMedia("(prefers-color-scheme: dark)");const autoChangeScheme=e=>{currentTheme=e.matches?"dark":"light",document.documentElement.setAttribute("data-theme",currentTheme)};document.addEventListener("DOMContentLoaded",function(){switchButton=document.querySelector(".theme-switcher"),currentTheme=detectCurrentScheme(),currentTheme=="dark"&&document.documentElement.setAttribute("data-theme","dark"),currentTheme=="auto"&&(autoChangeScheme(autoDefinedScheme),autoDefinedScheme.addListener(autoChangeScheme)),switchButton&&switchButton.addEventListener("click",switchTheme,!1),showContent()});function detectCurrentScheme(){return localStorage!==null&&localStorage.getItem(STORAGE_KEY)?localStorage.getItem(STORAGE_KEY):defaultTheme?defaultTheme:window.matchMedia?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":"light"}function switchTheme(){currentTheme=="dark"?(localStorage!==null&&localStorage.setItem(STORAGE_KEY,"light"),document.documentElement.setAttribute("data-theme","light"),currentTheme="light"):(localStorage!==null&&localStorage.setItem(STORAGE_KEY,"dark"),document.documentElement.setAttribute("data-theme","dark"),currentTheme="dark")}function showContent(){document.body.style.visibility="visible",document.body.style.opacity=1}</script></div></div><nav><a href=https://www.bpesquet.fr/bio/ title="Short bio">Short bio</a>
<a href=https://www.bpesquet.fr/teaching/ title=Teaching>Teaching</a>
<a href=https://www.bpesquet.fr/research/ title=Research>Research</a>
<a href=https://www.bpesquet.fr/posts/ title="Blog archive">Blog</a></nav><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></header><main id=main tabindex=-1><article class="post h-entry"><div class=post-header><header></header></div><nav id=TableOfContents><ul><li><a href=#terminology>Terminology</a><ul><li><a href=#decision-and-decision-making>Decision and decision-making</a></li><li><a href=#the-sequential-nature-of-decision-making>The sequential nature of decision-making</a></li><li><a href=#from-stimulus-to-response>From stimulus to response</a></li><li><a href=#speedaccuracy-tradeoff>Speed/accuracy tradeoff</a></li></ul></li><li><a href=#modeling-speeded-decision-making>Modeling speeded decision-making</a><ul><li><a href=#context>Context</a></li><li><a href=#the-cognitive-processes-of-decision-making>The cognitive processes of decision-making</a></li><li><a href=#sequential-sampling>Sequential sampling</a></li><li><a href=#accumulator-models>Accumulator models</a></li><li><a href=#random-walk-models>Random walk models</a></li><li><a href=#diffusion-models>Diffusion models</a></li><li><a href=#hybrid-models>Hybrid models</a></li><li><a href=#relationships-between-models>Relationships between models</a></li><li><a href=#multiple-choice-decisions>Multiple-choice decisions</a></li></ul></li><li><a href=#learning-and-decision-making>Learning and decision-making</a><ul><li><a href=#intertwined-cognitive-processes>Intertwined cognitive processes</a></li><li><a href=#bridging-the-modeling-gap>Bridging the modeling gap</a></li><li><a href=#common-choices>Common choices</a></li><li><a href=#the-rl-ddm-model>The RL-DDM model</a></li><li><a href=#the-rl-racing-diffusion-model>The RL-Racing Diffusion model</a></li><li><a href=#the-rl-advantage-racing-diffusion-model>The RL-Advantage Racing Diffusion model</a></li><li><a href=#model-comparison>Model comparison</a></li><li><a href=#multi-alternative-rl-ard>Multi-alternative RL-ARD</a></li></ul></li></ul></nav><div class="content e-content"><h1 id=introduction-to-the-theory-of-decision-making>Introduction to the theory of decision-making
<span><a href=#introduction-to-the-theory-of-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h1><h2 id=terminology>Terminology
<span><a href=#terminology><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h2><h3 id=decision-and-decision-making>Decision and decision-making
<span><a href=#decision-and-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>A <strong>decision</strong> is &ldquo;a deliberative process that results in the commitment to a categorical proposition.&rdquo; <a href=https://www.annualreviews.org/content/journals/10.1146/annurev.neuro.29.051605.113038>[Gold and Shadlen, 2007]</a></p><p>People make thousands of (big and small) decisions everyday. A few examples:</p><ul><li>Choosing what pair of socks to wear.</li><li>Deciding on a TV series to watch.</li><li>Choosing one&rsquo;s next car/bike.</li></ul><p><strong>Decision-making</strong> designates the cognitive process(es) resulting in a decision.</p><h3 id=the-sequential-nature-of-decision-making>The sequential nature of decision-making
<span><a href=#the-sequential-nature-of-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>Humans and animals make their decisions after a <strong>deliberation</strong> phase.</p><p>Many decisions are based on information that unfolds over time (example: cues for solving an homicide).</p><p>Even if all informative data is immediately available (example: a chess position), it has to be treated <strong>sequentially</strong> by our nervous system, reflecting its inability to process information simultaneously.</p><h3 id=from-stimulus-to-response>From stimulus to response
<span><a href=#from-stimulus-to-response><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p><strong>Decision-making</strong> can be formalized as the mapping from a stimulus to a response.</p><p>Time between stimulus and response execution is called <strong>Reaction Time</strong> or <strong>Response Time</strong> (RT) <a href=https://www.annualreviews.org/content/journals/10.1146/annurev-psych-122414-033645>[Forstmann et al., 2016]</a>, <a href=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.1039172/full>[Myers et al., 2022]</a>.</p><p>$$RT = T_e+T_d+T_r$$</p><p>$T_{er}= T_e+T_r$ is called <strong>non-decision time</strong>.</p><p><img src=images/response_time.png alt="Response Time"></p><h3 id=speedaccuracy-tradeoff>Speed/accuracy tradeoff
<span><a href=#speedaccuracy-tradeoff><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>All decisions are made under time pressure <a href=https://www.annualreviews.org/content/journals/10.1146/annurev-psych-122414-033645>[Forstmann et al., 2016]</a>. The balance between response time and accuracy is called the <strong>speed/accuracy trade-off</strong>.</p><p>It is at least partially under conscious control: decision-makers can decide to make faster decisions at the expense of an higher error rate, or slower, more accurate decisions <a href=https://www.sciencedirect.com/science/article/pii/S1364661316000255?via%3Dihub>[Ratcliff et al., 2016]</a>. This complicates the interpretation of behavioral data.</p><p>Ideally, what is needed is a way to evaluate data that considers not only accuracy and speed, but the interaction between them <a href=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.1039172/full>[Myers et al., 2022]</a>.</p><h2 id=modeling-speeded-decision-making>Modeling speeded decision-making
<span><a href=#modeling-speeded-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h2><h3 id=context>Context
<span><a href=#context><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>One approach to understanding decision-making is through <strong>computational models</strong>.</p><p>Several models have been developed to account for the speed/accuracy trade-off and explain how people and animals make decisions under time pressure.</p><p>Historically, most research on the dynamics of decision-making has been focused on simple, repeatable problems involving fast binary-choice decisions with one correct answer.</p><h4 id=task-examples>Task examples
<span><a href=#task-examples><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><ul><li>Lexical decision tasks: pressing one key if the stimulus is a word or another if it is a non-word.</li><li><a href=https://en.wikipedia.org/wiki/Stroop_effect>Stroop tasks</a>.</li><li>Saccadic flanker tasks: moving the eye in the direction indicated by a central stimulus, ignoring the directionality of flanker stimuli.</li><li><em>Random Dot Kinematogram</em> (RDK): judging whether a subset of dots move to the left or to the right.</li></ul><p><img src=images/rdk.png alt=RDK></p><h4 id=measures-of-interest>Measures of interest
<span><a href=#measures-of-interest><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><ul><li>Response times (RTs) for correct responses and for error responses.</li><li>Distributions of RTs across trials.</li><li>Proportion of correct responses (accuracy).</li></ul><h3 id=the-cognitive-processes-of-decision-making>The cognitive processes of decision-making
<span><a href=#the-cognitive-processes-of-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p><img src=images/decision-making_processes.png alt="Cognitive processes of decision-making"></p><p><a href=https://www.sciencedirect.com/science/article/pii/S1364661307000290?via%3Dihub>[Bogacz, 2007]</a></p><h3 id=sequential-sampling>Sequential sampling
<span><a href=#sequential-sampling><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>A popular class of models assumes that, on each trial, the decision maker accumulates noisy samples of information from the environment until a <strong>threshold</strong> of evidence is reached.</p><p>Such accumulation-to-threshold models are known as <strong>sequential sampling models</strong>, a.k.a. <strong>evidence accumulation models</strong>.</p><p>Different approaches to sequential sampling coexist. A key distinction is the number of <strong>accumulators</strong> (structures for gathering evidence in favor of one response) and whether they are independent from one another.</p><p>An accumulator is also called a <strong>Decision Variable</strong> (DV).</p><h4 id=example-sequential-sampling-for-rdk>Example: sequential sampling for RDK
<span><a href=#example-sequential-sampling-for-rdk><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p><img src=images/eam_rdk.png alt="Sequential sampling for RDK"></p><h4 id=the-sequential-sampling-model-family>The sequential sampling model family
<span><a href=#the-sequential-sampling-model-family><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p><img src=images/sequential_sampling_models.png alt="Sequential Sampling model landscape"></p><h3 id=accumulator-models>Accumulator models
<span><a href=#accumulator-models><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>These models, also known as <strong>race models</strong>, have independent accumulators (typically one per possible choice) and an <strong>absolute</strong> evidence response rule (two fixed thresholds, once for each accumulator). The process stops once one of the accumulators reaches its threshold.</p><p><img src=images/race_model.png alt="Illustration of an accumulator model"></p><h3 id=random-walk-models>Random walk models
<span><a href=#random-walk-models><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>These models use a <strong>relative</strong> evidence rule: a response is initiated as soon as the difference in accumulated evidence reaches a predefined threshold, also called a <strong>criterion</strong>.</p><p><img src=images/random_walk.png alt="Illustration of a random walk model"></p><h4 id=problem-example-the-gamblers-ruin>Problem example: the gambler&rsquo;s ruin
<span><a href=#problem-example-the-gamblers-ruin><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p>Two gamblers A and B have a (possibly different) starting capital and play a series of independant games against each other. Every game has a fixed chance $p$ of being won by gambler A. After each game, the winner obtains one unit of the other player’s capital. The process continues until one of the gamblers is bankrupt.</p><p>This problem can be modelised as a random walk, with $p$ representing the <strong>drift</strong> of the process. Depending on the value of $p$, the process will drift towards one of the thresholds (gambler B’s bankruptcy if $p>0.5$).</p><h4 id=mathematical-formulation>Mathematical formulation
<span><a href=#mathematical-formulation><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><ul><li>$K$: number of possible states of the world. For binary choices, $K=2$.</li><li>$h_k, k \in [1,K]$: hypothesis (state). Examples: dot movement type, presence of a stimulus, etc.</li><li>$H_k, k \in [1,K]$: choice associated with hypothesis $h_k$.</li><li>$P(h_k)$: probability that $h_k$ is true before obtaining any evidence about it.</li><li>$n$: number of evidences received.</li><li>$e_i, i \in [1,n]$: evidence (noisy information) and guiding commitment to a particular hypothesis $h_k$.</li><li>$P(e_i|h_k)$: likelihood (values that $e_i$ can attain when $h_k$ is true).</li></ul><h4 id=sequential-probability-ratio-test>Sequential Probability Ratio Test
<span><a href=#sequential-probability-ratio-test><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p>Particular form of <strong>sequential analysis</strong> for binary decisions ($K=2$) where the DV is constructed from multiple, independent pieces of evidence $e_1, e_2, \dots, e_n$ as the logarithm of the likelihood ratio between hypotheses $h_1$ and $h_2$.</p><p>$$DV_n = \sum_{i=1}^n log_e \frac{P(e_i|h_1)}{P(e_i|h_2)} = \sum_{i=1}^n w_i$$</p><ul><li>$w_i, i \in [1,n]$: weight of the $i$th evidence.</li></ul><p>The DV is updated with new pieces of evidence until reaching a criterion.</p><p>SPRT is the most efficient statistical test for deciding between two hypotheses on this kind of problem: it achieves a desired error rate with the smallest number of samples, on average [Wald and Wolfowitz, 1948).</p><h4 id=problem-example-trick-or-fair-coin>Problem example: trick or fair coin
<span><a href=#problem-example-trick-or-fair-coin><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p>Two coins are placed in a bag: one is fair (50% chance of obtaining heads or tails when tossing it), the other not (60/40). One of the coins is drawn from the bag: is it a trick ($h_1$) or a fair ($h_2$) coin? How many tosses are needed for this decision?</p><p>$$\forall i \in[1,n], w_i=
\begin{cases}
\log_e \frac{P(e_{heads}|h_1)}{P(e_{heads}|h_2)} = \log_e \frac{0.6}{0.5} = 0.182 & \text{if toss gives &ldquo;heads&rdquo;} \
\log_e \frac{P(e_{tails}|h_1)}{P(e_{tails}|h_2)} = \log_e \frac{0.4}{0.5} = -0.223 & \text{if toss gives &ldquo;tails&rdquo;}
\end{cases}$$</p><p>$$\text{If}\ DV_n \ge \frac{1-\alpha}{\alpha}, \text{answer &ldquo;trick&rdquo;.}\ \text{If}\ DV_n \le \frac{\alpha}{1-\alpha}, \text{answer &ldquo;fair&rdquo;.}$$</p><p>With $\alpha = P(H_2|h_1) = P(H_1|h_2)$ the probability of misidentifying a coin.</p><p>For $\alpha=0.05$, a decision happens when $|DV_n| \ge \log_e(19)$.</p><h3 id=diffusion-models>Diffusion models
<span><a href=#diffusion-models><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>When the evidence is continously sampled from a distribution in infinitesimal time steps, the process is termed <strong>diffusion</strong> with drift $v$. When $v$ is constant, this process is known as <a href=https://en.wikipedia.org/wiki/Brownian_motion>Brownian motion</a> or Wiener diffusion process <a href=https://www.annualreviews.org/content/journals/10.1146/annurev.neuro.29.051605.113038>[Gold and Shadlen, 2007]</a>.</p><p><img src=images/diffusion_model.png alt="Diffusion model"></p><blockquote><p>The diffusion models for decision-making are not to be confused with the <a href=https://en.wikipedia.org/wiki/Diffusion_model>diffusion models of Machine Learning</a>.</p></blockquote><h4 id=the-diffusion-decision-model>The Diffusion Decision Model
<span><a href=#the-diffusion-decision-model><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p>This model, also called <strong>Drift Diffusion Model (DDM)</strong>, is a sequential sampling model for binary choices in continuous environments <a href="https://direct.mit.edu/neco/article-abstract/20/4/873/7299/The-Diffusion-Decision-Model-Theory-and-Data-for?redirectedFrom=fulltext">[Ratcliff and McKoon, 2008]</a>.</p><p>Originally designed in the 1970&rsquo;s [Ratcliff, 1978], it has recently experienced a surge in popularity. A growing body of literature is using the DDM to elucidate the cognitive processes of decision-making.</p><h5 id=parameters>Parameters
<span><a href=#parameters><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h5><table><thead><tr><th>Name</th><th>Description</th><th>Typical range</th><th>Implements</th></tr></thead><tbody><tr><td>$a$</td><td>Boundary separation</td><td>$[0.5,2]$ (in arbitrary units)</td><td>Speed/accuracy trade-off</td></tr><tr><td>$z$</td><td>Starting point</td><td>$[0,1]$ (as proportion of $a$)</td><td>Response bias</td></tr><tr><td>$v$</td><td>Drift rate</td><td>$[-5,5]$</td><td>Speed of evidence accumulation processing</td></tr><tr><td>$T_{er}$</td><td>Non-decision time</td><td>$[0.1,0.5]$ (in seconds)</td><td>Neurological processes for stimulus encoding and motor response</td></tr></tbody></table><p><img src=images/ddm.png alt=DDM></p><h5 id=mathematical-formulation-1>Mathematical formulation
<span><a href=#mathematical-formulation-1><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h5><p>The DDM assumes that evidence accumulation is governed by:</p><p>$$dx = vdt + sW$$</p><ul><li>$x$: accumulated evidence.</li><li>$v$: drift rate (speed of evidence accumulation).</li><li>$dt$: time unit. When $dt = 0$, the integration process is continuous in time.</li><li>$W$: within-trial accumulation white noise.</li><li>$s$: standard deviation of $W$.</li></ul><h5 id=advantages>Advantages
<span><a href=#advantages><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h5><ul><li>Experimental validation has shown that:<ul><li>DDM parameters do capture recognizable, and at least partly separable, cognitive processes.</li><li>DDM provides an explanation for some of the dynamics of neuronal activity in brains.</li></ul></li><li>Several software packages like <a href=https://hddm.readthedocs.io/en/latest/>HDDM</a> facilitate fitting the model to experimental data, or generating simulated data.</li></ul><h5 id=applications>Applications
<span><a href=#applications><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h5><h6 id=behavioral-analysis>Behavioral analysis
<span><a href=#behavioral-analysis><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h6><ul><li><strong>Aging</strong>: DDM-based studies showed that older adults had slower non-decision times and set wider boundaries, but their drift rates were not always lower than those of young adults.</li><li><strong>IQ</strong>: DDM-based analyses showed showed that drift rate varied with IQ, but boundary separation and nondecision time did not.</li><li>Other studies showed that <strong>sleep deprivation</strong> and <strong>alcohol consumption</strong> lower drift rate, but have either small or no effect on boundary separation and non-decision time.</li><li>&mldr;</li></ul><h6 id=low-level-neuroscience>Low-level neuroscience
<span><a href=#low-level-neuroscience><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h6><p>Studies <a href=https://www.sciencedirect.com/science/article/pii/S1364661300015679?via%3Dihub>[Gold and Shadlen, 2001]</a> uses DDM as inspiration to interpret neuron firing rates in monkeys as evidence accumulation until a threshold is reached.</p><p><img src=images/ddm_firing_rate.png alt="Firing rate in monkeys"></p><h6 id=high-level-neuroscience>High-level neuroscience
<span><a href=#high-level-neuroscience><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h6><p>Studies correlate parameter estimates from DDM models to the blood-oxygen-level dependent signal obtained from fMRI experiments in perceptual decision-making.</p><p><img src=images/ddm_brain_activity.png alt="Brain activity & DDM"></p><h5 id=extension-to-dynamic-thresholds>Extension to dynamic thresholds
<span><a href=#extension-to-dynamic-thresholds><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h5><p>Collapsing-bound models translate the fact that in some cases, decisions are based on less and less evidence as time passes.</p><p><img src=images/ddm_dyn_thresholds.png alt="DDM extension:dynamic thresholds"></p><h3 id=hybrid-models>Hybrid models
<span><a href=#hybrid-models><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><h4 id=the-leaky-competing-accumulator-model>The Leaky Competing Accumulator model
<span><a href=#the-leaky-competing-accumulator-model><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p>This model [Usher and McClelland, 2001] is based on gradual and stochastic accumulation of information in non-linear decision units with <strong>leakage</strong> (or decay of activation) and competition through <strong>lateral inhibition</strong>.</p><h3 id=relationships-between-models>Relationships between models
<span><a href=#relationships-between-models><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>Cortical models ([Shadlen and Newsome, 2001], [Usher and McClelland, 2001], <a href=https://www.sciencedirect.com/science/article/pii/S0896627302010929?via%3Dihub>[Wang, 2002]</a>) can be reduced to the diffusion model for parameter values that optimize their performance <a href=https://www.sciencedirect.com/science/article/pii/S1364661307000290?via%3Dihub>[Bogacz, 2007]</a>.</p><hr><p><img src=images/ddm_cortical_models.png alt="DDM & cortical models"></p><h3 id=multiple-choice-decisions>Multiple-choice decisions
<span><a href=#multiple-choice-decisions><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><h4 id=multihypothesis-sequential-probability-ratio-test>Multihypothesis Sequential Probability Ratio Test
<span><a href=#multihypothesis-sequential-probability-ratio-test><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><ul><li>Extension of SPRT to ternary choices in which the rate of integration depends on the fixation of the visual stimulus, as measured through eye-tracking <a href=https://www.pnas.org/doi/full/10.1073/pnas.1101328108>[Krajbich and Rangel, 2011]</a>.</li><li>A DV is computed for each item based on the evidence accumulated for that item compared with the highest accumulated evidence for the other items (<em>best-vs-next</em> approach).</li></ul><hr><p><img src=images/msprt.png alt=MSPRT></p><h4 id=hicks-law>Hick&rsquo;s law
<span><a href=#hicks-law><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><ul><li>Increasing the number of choices will increase the decision time <em>logarithmically</em>.</li><li>Race models with one accumulator per possible choice produce the opposite trend (more accumulators $\Rightarrow$ faster RT).</li></ul><h4 id=the-advantage-linear-ballistic-accumulator-model>The Advantage Linear Ballistic Accumulator model
<span><a href=#the-advantage-linear-ballistic-accumulator-model><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p>In this model <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Frev0000166">[Van Ravenzwaaij et al., 2020]</a>, each of the $n$ possible choices is associated to $n-1$ accumulators, each of them driven by the difference (&ldquo;advantage&rdquo;) in evidence versus another response.</p><h5 id=alba-model-for-binary-choice>ALBA model for binary choice
<span><a href=#alba-model-for-binary-choice><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h5><p>$$v_{1-2} = v_0 + w_d(S_1 - S_2) + w_s(S_1 + S_2)$$</p><p>$$v_{2-1} = v_0 + w_d(S_2 - S_1) + w_s(S_1 + S_2)$$</p><ul><li>$v_{i-j}$: drift rate for the accumulator associated with the advantage of stimulus $i$ over $j$.</li><li>$S_i$: evidence for stimulus $i$.</li><li>$v_0$: bias parameter.</li><li>$w_d \in \mathbb{R}^+$: difference weight.</li><li>$w_s \in \mathbb{R}^+$: sum weight.</li></ul><h5 id=alba-model-for-ternary-choice>ALBA model for ternary choice
<span><a href=#alba-model-for-ternary-choice><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h5><p><em>Win-all</em> strategy: all accumulators for a choice need to reach their threshold before commiting to a decision.</p><p><img src=images/alba_winall.png alt="ALBA model: win-all strategy"></p><h2 id=learning-and-decision-making>Learning and decision-making
<span><a href=#learning-and-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h2><h3 id=intertwined-cognitive-processes>Intertwined cognitive processes
<span><a href=#intertwined-cognitive-processes><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><ul><li>Learning processes refine the internal preferences and representations that inform decisions.</li><li>The outcomes of decisions underpin feedback-driven learning.</li></ul><h3 id=bridging-the-modeling-gap>Bridging the modeling gap
<span><a href=#bridging-the-modeling-gap><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><ul><li><p><strong>Feedback-driven learning models</strong>, typically using <em>softmax</em> to map action values to choices, do not provide a description of the cognitive processes that lead to a specific decision, and disregard RT.</p></li><li><p><strong>Evidence accumulation models</strong> like the DDM are typically applied to tasks that minimize the influence of learning. Very few attempts have been made to adapt these models to situations in which decisions are followed by <strong>rewards</strong>, thereby producing <strong>learning effects</strong>.</p></li><li><p>Recent efforts are trying to combine <a href=https://github.com/bpesquet/mlcourse/blob/main/notes/rl_introduction/README.md>Reinforcement Learning</a> and EAM into joint models that should be able to:</p><ul><li>predict choices and RT;</li><li>describe how learning affects the decision process.</li></ul></li></ul><h3 id=common-choices>Common choices
<span><a href=#common-choices><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><h4 id=model-design>Model design
<span><a href=#model-design><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p>The RL-EAM model family has two components:</p><ul><li>a <strong>learning</strong> component, using RL to update options&rsquo; value representations (the expected rewards for each choice), known as <em>Q-values</em>, after each trial;</li><li>a <strong>decision</strong> component, relying on a EAM to map value representations to the final choice for a trial.</li></ul><h4 id=q-values-update>Q-values update
<span><a href=#q-values-update><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h4><p>All models update the Q-values of possible choices according to the <em>delta update rule</em>:</p><p>$$Q_{i,t+1} = Q_{i,t} + \alpha(r_t - Q_{i,t})$$</p><ul><li>$Q_{i,t}$: value representation of choice $i$ on trial $t$.</li><li>$r_t$: reward received on trial $t$.</li><li>$\alpha \in [0,1]$: learning rate.</li></ul><p>The difference $r_t - Q_{i,t}$ between actual reward and value representation is called the <em>reward prediction error</em>.</p><h3 id=the-rl-ddm-model>The RL-DDM model
<span><a href=#the-rl-ddm-model><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>This model <a href=https://link.springer.com/article/10.3758/s13423-018-1554-2>[Fontanesi et al., 2019]</a> assumes that the drift rate depends linearly on the difference of value representations between the two possible choices.</p><p>$$v_t = w(Q_{1,t}-Q_{2,t})$$</p><p>$$dx = w(Q_1-Q_2)dt + sW$$</p><ul><li>$v_t$: drift rate at time step $t$.</li><li>$w$: weighting factor.</li></ul><h3 id=the-rl-racing-diffusion-model>The RL-Racing Diffusion model
<span><a href=#the-rl-racing-diffusion-model><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>This model assumes that accumulators independently accrue evidence for one choice option each, both racing toward a common threshold (assuming no response bias).</p><p>$$v_t = V_0 + wQ_i$$</p><p>$$dx_i = (V_0 + wQ_i)dt +sW$$</p><ul><li>$x_i$: accumulated evidence for choice $i$.</li><li>$V_0$: drift rate in the absence of any evidence, identical accross accumulators (additive urgency signal).</li></ul><h3 id=the-rl-advantage-racing-diffusion-model>The RL-Advantage Racing Diffusion model
<span><a href=#the-rl-advantage-racing-diffusion-model><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>This model <a href=https://elifesciences.org/articles/63055>[Miletić et al., 2021]</a> uses an ALBA architecture <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Frev0000166">[Van Ravenzwaaij et al., 2020]</a> as its decision component.</p><p>$$dx_1 = \big(V_0 + w_d(Q_1 - Q_2) + w_s(Q_1 + Q_2)\big)dt + sW$$</p><p>$$dx_2 = \big(V_0 + w_d(Q_2 - Q_1) + w_s(Q_1 + Q_2)\big)dt + sW$$</p><h3 id=model-comparison>Model comparison
<span><a href=#model-comparison><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p><img src=images/rl-eam.png alt="Three RL-EAM models"></p><h3 id=multi-alternative-rl-ard>Multi-alternative RL-ARD
<span><a href=#multi-alternative-rl-ard><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>Its ALBA decision model extends naturally to multi-alternative choice tasks.</p><p><img src=images/rl-ard_multi.png alt="Multi RL-ARD"></p></div><div class=post-info><div class="post-date dt-published"><a class=u-url href=/talks/decision-making/><time datetime=2024-01-29>January 29, 2024</time></a>
[Last modified: <time datetime=2024-12-04>December 4, 2024</time>]</div><a class="post-hidden-url u-url" href=https://www.bpesquet.fr/talks/decision-making/>https://www.bpesquet.fr/talks/decision-making/</a>
<a href=https://www.bpesquet.fr class="p-name p-author post-hidden-author h-card" rel=me>Baptiste Pesquet</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://www.bpesquet.fr/tags/decision-making/>#decision-making</a></li></ul></div></div></article><div class="pagination post-pagination"><div class="left pagination-item"><a href=/talks/confidence/>Confidence in decision-making</a></div><div class="right pagination-item disabled"></div></div></main><footer class=common-footer><div class=common-footer-bottom><div class=copyright><p>© Baptiste Pesquet, 2024<br>Powered by <a target=_blank rel="noopener noreferrer" href=https://gohugo.io/>Hugo</a>, theme <a target=_blank rel="noopener noreferrer" href=https://github.com/mitrichius/hugo-theme-anubis>Anubis</a>.<br></p></div></div><p class="h-card vcard"><a href=https://www.bpesquet.fr class="p-name u-url url fn" rel=me>Baptiste Pesquet</a>
/
<a class="p-email u-email email" rel=me href=mailto:bpesquet%20[at]%20gmail%20[dot]%20com>bpesquet [at] gmail [dot] com</a></p></footer></div></body></html>