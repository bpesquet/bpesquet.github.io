<!doctype html><html lang=en data-theme><head><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><title>Towards metacognitive agents: integrating confidence in sequential decision-making - Baptiste Pesquet</title><meta name=description content="Towards metacognitive agents: integrating confidence in sequential decision-making Confidence in natural cognition Decision-making as a sequential process A decision is a deliberative process leading to a choice. Decision-makers need time to collect and process informative cues. Decision-making is often modeled as an accumulation-to-threshold process [Gold and Shadlen, 2007]. The balance between response time and accuracy (when available) is called the Speed/Accuracy Trade-off [Heitz, 2014]. Models of sequential decision-making For binary choices, a popular model is the Diffusion Decision Model [Ratcliff and McKoon, 2008]."><link rel=icon type=image/x-icon href=https://www.bpesquet.fr/favicon.ico><link rel=apple-touch-icon-precomposed href=https://www.bpesquet.fr/favicon.png><style>body{visibility:hidden;opacity:0}</style><noscript><style>body{visibility:visible;opacity:1}</style></noscript><link rel=stylesheet href=https://www.bpesquet.fr/css/style.min.ecd6d68ec75f136aa2ef44e76818d4e46cf4ee45f39dae3684c8b4232785015c.css integrity="sha256-7NbWjsdfE2qi70TnaBjU5Gz07kXzna42hMi0IyeFAVw="><script src=https://www.bpesquet.fr/js/script.min.74bf1a3fcf1af396efa4acf3e660e876b61a2153ab9cbe1893ac24ea6d4f94ee.js type=text/javascript integrity="sha256-dL8aP88a85bvpKzz5mDodrYaIVOrnL4Yk6wk6m1PlO4="></script><meta property="og:title" content="Towards metacognitive agents: integrating confidence in sequential decision-making"><meta property="og:description" content="Towards metacognitive agents: integrating confidence in sequential decision-making Confidence in natural cognition Decision-making as a sequential process A decision is a deliberative process leading to a choice. Decision-makers need time to collect and process informative cues. Decision-making is often modeled as an accumulation-to-threshold process [Gold and Shadlen, 2007]. The balance between response time and accuracy (when available) is called the Speed/Accuracy Trade-off [Heitz, 2014]. Models of sequential decision-making For binary choices, a popular model is the Diffusion Decision Model [Ratcliff and McKoon, 2008]."><meta property="og:type" content="article"><meta property="og:url" content="https://www.bpesquet.fr/presentations/imn-day-2025/"><meta property="article:section" content="presentations"><meta property="article:published_time" content="2025-05-05T10:04:27+02:00"><meta property="article:modified_time" content="2025-05-07T15:55:03+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Towards metacognitive agents: integrating confidence in sequential decision-making"><meta name=twitter:description content="Towards metacognitive agents: integrating confidence in sequential decision-making Confidence in natural cognition Decision-making as a sequential process A decision is a deliberative process leading to a choice. Decision-makers need time to collect and process informative cues. Decision-making is often modeled as an accumulation-to-threshold process [Gold and Shadlen, 2007]. The balance between response time and accuracy (when available) is called the Speed/Accuracy Trade-off [Heitz, 2014]. Models of sequential decision-making For binary choices, a popular model is the Diffusion Decision Model [Ratcliff and McKoon, 2008]."><script async src="https://www.googletagmanager.com/gtag/js?id=G-4DNVMNCRYK"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-4DNVMNCRYK",{anonymize_ip:!1})}</script></head><body><a class=skip-main href=#main>Skip to main content</a><div class=container><header class=common-header><div class=header-top><div class=header-top-left><h1 class=site-title><a href=/>Baptiste Pesquet</a></h1><ul class=social-icons><li><a href="mailto:bpesquet [at] gmail [dot] com" title=Email rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M464 64H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 4e2V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V4e2H48z"/></svg></span></a></li><li><a href=https://github.com/bpesquet title=Github rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></li><li><a href="https://scholar.google.fr/citations?hl=fr&amp;user=0KJ7JkMAAAAJ" title="Google scholar" rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M390.9 298.5s0 .1.1.1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7 4.4-7.6 9.4-14.7 15-21.3 27.4-32.6 68.5-53.3 114.4-53.3 33.6.0 64.6 11.1 89.6 29.9 9.1 6.9 17.4 14.7 24.8 23.5 5.6 6.6 10.6 13.8 15 21.3 2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/></svg></span></a></li><li><a href=https://www.linkedin.com/in/bpesquet title=Linkedin rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M100.3 448H7.4V148.9h92.9zM53.8 108.1C24.1 108.1.0 83.5.0 53.8a53.8 53.8.0 01107.6.0c0 29.7-24.1 54.3-53.8 54.3zM447.9 448h-92.7V302.4c0-34.7-.7-79.2-48.3-79.2-48.3.0-55.7 37.7-55.7 76.7V448h-92.8V148.9h89.1v40.8h1.3c12.4-23.5 42.7-48.3 87.9-48.3 94 0 111.3 61.9 111.3 142.3V448z"/></svg></span></a></li><li><a href=https://bsky.app/profile/bpesquet.bsky.social title=Bluesky rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill="currentcolor" d="M123.6 34.5C190 84.6 261.5 186 287.8 240.5 314 186 385.5 84.5 452 34.5c48-36.1 125.6-64.1 125.6 24.9.0 17.8-10.1 149.2-16.1 170.5-20.7 74.2-96.1 93.1-163.1 81.6 117.2 20 147 86.3 82.6 152.6-122.3 125.9-175.8-31.6-189.5-72-2.5-7.5-3.7-10.9-3.7-7.9.0-3.1-1.2.4-3.7 7.9-13.7 40.4-67.2 197.9-189.5 72C30.2 397.8 60 331.5 177.2 311.5c-67 11.4-142.4-7.5-163.1-81.7C8.1 208.5-2 77.1-2 59.3c0-88.9 77.7-61 125.6-24.9z"/></svg></span></a></li><li><a href=https://www.youtube.com/c/../@bpesquet title=Youtube rel=me><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg></span></a></li></ul></div><div class=header-top-right><div class=theme-switcher><span class=inline-svg><svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 290 290"><path fill="currentcolor" d="M142.959.0C64.131.0.0 64.132.0 142.96s64.131 142.959 142.959 142.959 142.96-64.131 142.96-142.959C285.919 64.132 221.787.0 142.959.0zm0 260.919V142.96 25c65.043.0 117.96 52.917 117.96 117.96.0 65.043-52.917 117.959-117.96 117.959z"/></svg></span></div><script>const STORAGE_KEY="user-color-scheme",defaultTheme="auto";let currentTheme,switchButton,autoDefinedScheme=window.matchMedia("(prefers-color-scheme: dark)");const autoChangeScheme=e=>{currentTheme=e.matches?"dark":"light",document.documentElement.setAttribute("data-theme",currentTheme)};document.addEventListener("DOMContentLoaded",function(){switchButton=document.querySelector(".theme-switcher"),currentTheme=detectCurrentScheme(),currentTheme=="dark"&&document.documentElement.setAttribute("data-theme","dark"),currentTheme=="auto"&&(autoChangeScheme(autoDefinedScheme),autoDefinedScheme.addListener(autoChangeScheme)),switchButton&&switchButton.addEventListener("click",switchTheme,!1),showContent()});function detectCurrentScheme(){return localStorage!==null&&localStorage.getItem(STORAGE_KEY)?localStorage.getItem(STORAGE_KEY):defaultTheme?defaultTheme:window.matchMedia?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":"light"}function switchTheme(){currentTheme=="dark"?(localStorage!==null&&localStorage.setItem(STORAGE_KEY,"light"),document.documentElement.setAttribute("data-theme","light"),currentTheme="light"):(localStorage!==null&&localStorage.setItem(STORAGE_KEY,"dark"),document.documentElement.setAttribute("data-theme","dark"),currentTheme="dark")}function showContent(){document.body.style.visibility="visible",document.body.style.opacity=1}</script></div></div><nav><a href=https://www.bpesquet.fr/bio/ title="Short bio">Short bio</a>
<a href=https://www.bpesquet.fr/teaching/ title=Teaching>Teaching</a>
<a href=https://www.bpesquet.fr/research/ title=Research>Research</a>
<a href=https://www.bpesquet.fr/talks/ title="Talks and presentations">Talks</a>
<a href=https://www.bpesquet.fr/posts/ title="Blog archive">Blog</a></nav><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></header><main id=main tabindex=-1><article class="post h-entry"><div class=post-header><header><h1 class="p-name post-title">Towards metacognitive agents: integrating confidence in sequential decision-making</h1></header></div><nav id=TableOfContents><ul><li><a href=#confidence-in-natural-cognition>Confidence in natural cognition</a><ul><li><a href=#decision-making-as-a-sequential-process>Decision-making as a sequential process</a></li><li><a href=#models-of-sequential-decision-making>Models of sequential decision-making</a></li><li><a href=#confidence-in-decision-making>Confidence in decision-making</a></li><li><a href=#computing-confidence-in-sequential-decision-making-models>Computing confidence in sequential decision-making models</a></li><li><a href=#confidence-as-a-doorway-to-metacognition>Confidence as a doorway to metacognition</a></li><li><a href=#an-emerging-field-the-neuroscience-of-confidence>An emerging field: the neuroscience of confidence</a></li></ul></li><li><a href=#proposed-approach>Proposed approach</a><ul><li><a href=#agent-architecture>Agent architecture</a></li><li><a href=#experimental-validation>Experimental validation</a></li><li><a href=#preliminary-results>Preliminary results</a></li><li><a href=#future-works>Future works</a></li></ul></li><li><a href=#thanks-for-your-attention>Thanks for your attention!</a></li></ul></nav><div class="content e-content"><style scoped>img{padding-right:40px}</style><h1 id=towards-metacognitive-agents-integrating-confidence-in-sequential-decision-making>Towards metacognitive agents: integrating confidence in sequential decision-making
<span><a href=#towards-metacognitive-agents-integrating-confidence-in-sequential-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h1><h2 id=confidence-in-natural-cognition>Confidence in natural cognition
<span><a href=#confidence-in-natural-cognition><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h2><h3 id=decision-making-as-a-sequential-process>Decision-making as a sequential process
<span><a href=#decision-making-as-a-sequential-process><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><ul><li>A <strong>decision</strong> is a deliberative process leading to a <strong>choice</strong>.</li><li>Decision-makers need <strong>time</strong> to collect and process informative cues.</li><li>Decision-making is often modeled as an <strong>accumulation-to-threshold</strong> process [<a href=https://www.annualreviews.org/doi/10.1146/annurev.neuro.29.051605.113038>Gold and Shadlen, 2007</a>].</li><li>The balance between response time and accuracy (when available) is called the <strong>Speed/Accuracy Trade-off</strong> [<a href=https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2014.00150/full>Heitz, 2014</a>].</li></ul><h3 id=models-of-sequential-decision-making>Models of sequential decision-making
<span><a href=#models-of-sequential-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><div class=columns><div><p>For binary choices, a popular model is the <strong>Diffusion Decision Model</strong> [<a href=https://direct.mit.edu/neco/article/20/4/873-922/7299>Ratcliff and McKoon, 2008</a>].</p><p><img src=images/forstmannSequentialSamplingModels2016_1.png alt="Illustration of the DDM model"></p><p><em>Image credits: [<a href=https://doi.org/10.1146/annurev-psych-122414-033645>Forstmann et al., 2016</a>]</em></p></div><div><p>Multi-alternative decisions are often modeled as a <strong>race</strong> between accumulators for each possible choice.</p><p><img src=images/mamassianVisualConfidence2016_1.png alt="Illustration of a race model"></p><p><em>Image credits: [<a href=https://www.annualreviews.org/doi/10.1146/annurev-vision-111815-114630>Mamassian, 2016</a>]</em></p></div></div><h3 id=confidence-in-decision-making>Confidence in decision-making
<span><a href=#confidence-in-decision-making><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><ul><li><strong>Uncertainty</strong> is inherent to all stages of neural computation [<a href=https://doi.org/10.1146/annurev-psych-022423-032425>Fleming, 2024</a>].<ul><li>It refers to probabilistic representations of information in the brain.</li></ul></li><li><strong>Confidence</strong> quantifies the degree of <strong>certainty</strong> associated with a decision.<ul><li>It refers to scalar values derived from those distributions [<a href=https://linkinghub.elsevier.com/retrieve/pii/S0896627315008284>Meyniel et al., 2015</a>].</li></ul></li><li>More formally, confidence can be defined as the <strong>probability</strong> that a choice is correct given the evidence [<a href=https://www.nature.com/articles/nn.4240>Pouget et al., 2016</a>].</li></ul><h3 id=computing-confidence-in-sequential-decision-making-models>Computing confidence in sequential decision-making models
<span><a href=#computing-confidence-in-sequential-decision-making-models><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><div class=columns><div><p>In <strong>decisional focus models</strong>, confidence is directly indexed by the state of evidence at the time of choice.</p><p><img src=images/kepecsNeuralCorrelatesComputation2008_1.png alt="Race model with BoE"></p><p><em>Image credits: <a href=https://www.nature.com/articles/nature07200>Kepecs et al., 2008</a></em></p></div><div><p><strong>Post-decisional focus models</strong> posit that evidence accumulation goes on after decision time to account for confidence.</p><p><img src=images/pleskacTwostageDynamicSignal2010_1.png alt="2DSD model"></p><p><em>Image credits: <a href=https://doi.apa.org/doi/10.1037/a0019737>Pleskac and Busemeyer, 2008</a></em></p></div></div><h3 id=confidence-as-a-doorway-to-metacognition>Confidence as a doorway to metacognition
<span><a href=#confidence-as-a-doorway-to-metacognition><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><ul><li><strong>Metacognition</strong> is the ability to <strong>monitor</strong> and <strong>regulate</strong> one&rsquo;s cognitive processes [<a href=https://www.semanticscholar.org/paper/Metacognition-and-Cognitive-Monitoring%3A-A-New-Area-Flavell/ee652f0f63ed5b0cfe0af4cb4ea76b2ecf790c8d>Flavell, 1979</a>].<ul><li>Example: should I study more (or differently) for this exam?</li></ul></li><li>As part of metacognitive monitoring, confidence judgments may inform the processes of <strong>cognitive control</strong> [<a href=http://journal.frontiersin.org/article/10.3389/fnhum.2014.00443/abstract>Fleming and Lau, 2014</a>].</li></ul><h3 id=an-emerging-field-the-neuroscience-of-confidence>An emerging field: the neuroscience of confidence
<span><a href=#an-emerging-field-the-neuroscience-of-confidence><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><ul><li><p>Activity in the <strong>parietal cortex</strong> seems related to evidence accumulation during decision-making.</p></li><li><p><strong>Separate</strong> and perhaps <strong>multiple</strong> brain areas are involved in confidence monitoring and reporting [<a href=https://linkinghub.elsevier.com/retrieve/pii/S0149763415001025>Grimaldi et al., 2015</a>]:</p><ul><li>Importance of the prefrontal cortex, more precisely the <strong>ventromedial prefrontal cortex</strong> (vmPFC), in the formation of confidence.</li><li>Firing rates of many single neurons in the <strong>orbitofrontal cortex</strong> (OFC) of rats match confidence models [<a href=https://www.nature.com/articles/nature07200>Kepecs et al., 2008</a>].</li></ul></li></ul><h2 id=proposed-approach>Proposed approach
<span><a href=#proposed-approach><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h2><h3 id=agent-architecture>Agent architecture
<span><a href=#agent-architecture><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>Model combining:</p><ul><li>a <strong>decision module</strong> based on an evidence accumulation model;</li><li>a <strong>metacognitive module</strong> in which confidence is used to tune the decision hyperparameters: decision threshold and evidence integration rate [<a href=http://biorxiv.org/lookup/doi/10.1101/2024.10.03.616475>Desender and Verguts, 2024</a>].</li></ul><h3 id=experimental-validation>Experimental validation
<span><a href=#experimental-validation><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><p>Model was assessed on a classic <strong>perceptual task</strong>: Random Dot Motion discrimination.</p><p><img src=images/pesquetAlexandre2025_1.png alt="Confident agent model"></p><h3 id=preliminary-results>Preliminary results
<span><a href=#preliminary-results><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><div class=columns><div><p>High dot motion coherence</p><p><img src=images/pesquetAlexandre2025_2.png alt="First model results"></p></div><div><p>Low coherence</p><p><img src=images/pesquetAlexandre2025_3.png alt="First model results"></p></div></div><ul><li>Confidence is correlated with dot motion coherence, as is (oppositely) decision time.</li><li>Model is able to implement the SAT.</li></ul><h3 id=future-works>Future works
<span><a href=#future-works><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h3><ul><li>Refine the hyperparameters tuning process.</li><li>Add different metacognitive strategies.</li><li>Implement model on a human/robot collaborative task.</li><li>&mldr;</li></ul><h2 id=thanks-for-your-attention>Thanks for your attention!
<span><a href=#thanks-for-your-attention><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/></svg></a></span></h2><p>Any questions?</p></div><div class=post-info><div class="post-date dt-published"><a class=u-url href=/presentations/imn-day-2025/><time datetime=2025-05-05>May 5, 2025</time></a>
[Last modified: <time datetime=2025-05-07>May 7, 2025</time>]</div><a class="post-hidden-url u-url" href=https://www.bpesquet.fr/presentations/imn-day-2025/>https://www.bpesquet.fr/presentations/imn-day-2025/</a>
<a href=https://www.bpesquet.fr class="p-name p-author post-hidden-author h-card" rel=me>Baptiste Pesquet</a><div class=post-taxonomies><ul class=post-tags><li><a href=https://www.bpesquet.fr/tags/decision-making/>#decision-making</a></li><li><a href=https://www.bpesquet.fr/tags/confidence/>#confidence</a></li></ul></div></div></article><div class="pagination post-pagination"><div class="left pagination-item disabled"></div><div class="right pagination-item"><a href=/presentations/chembiona-2925/>Artificial Intelligence: past, present, future(s)</a></div></div></main><footer class=common-footer><div class=common-footer-bottom><div class=copyright><p>Â© Baptiste Pesquet, 2025<br>Powered by <a target=_blank rel="noopener noreferrer" href=https://gohugo.io/>Hugo</a>, theme <a target=_blank rel="noopener noreferrer" href=https://github.com/mitrichius/hugo-theme-anubis>Anubis</a>.<br></p></div></div><p class="h-card vcard"><a href=https://www.bpesquet.fr class="p-name u-url url fn" rel=me>Baptiste Pesquet</a>
/
<a class="p-email u-email email" rel=me href=mailto:bpesquet%20[at]%20gmail%20[dot]%20com>bpesquet [at] gmail [dot] com</a></p></footer></div></body></html>